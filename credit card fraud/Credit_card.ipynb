{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO2qzKGeL38D"
   },
   "source": [
    "# Credit Card Fraud Detection::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDRR-9y5L7kT",
    "outputId": "c36f3eb0-6a8c-4171-9d63-a029110a150f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U86cEKtjL38K"
   },
   "source": [
    "Download dataset from this link:\n",
    "\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfAqLAvZL38K"
   },
   "source": [
    "# Description about dataset::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yi8R9_nbL38L"
   },
   "source": [
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
    "\n",
    "\n",
    "### Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Px3csygjL38L"
   },
   "source": [
    "# WORKFLOW :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLy8zHpmL38M"
   },
   "source": [
    "1.Load Data\n",
    "\n",
    "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
    "\n",
    "3.Standardized the Input Variables. \n",
    "\n",
    "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
    "\n",
    "5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
    "\n",
    "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "\n",
    "7.Train the Model with Epochs (100).\n",
    "\n",
    "8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "\n",
    "9.Prediction should be > 92%\n",
    "10.Evaluation Step\n",
    "11Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmtrpNa9L38M"
   },
   "source": [
    "# Task::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--ZU2ItML38M"
   },
   "source": [
    "## Identify fraudulent credit card transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvVH1oiLL38M",
    "outputId": "4df76110-41f5-4e49-d259-e7f20c7f114a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/credit-cart\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/credit-cart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxxNJCUdTlrl"
   },
   "source": [
    "1.Load **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KY7a9GOqL38N"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "df =pd.read_csv('./creditcard.csv/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "D6cVuB89L38P",
    "outputId": "ac2db8f5-e3c5-43f4-a60a-1a3f8d3067f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>-1.593105</td>\n",
       "      <td>2.711941</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.991691</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>-0.150189</td>\n",
       "      <td>0.915802</td>\n",
       "      <td>1.214756</td>\n",
       "      <td>-0.675143</td>\n",
       "      <td>1.164931</td>\n",
       "      <td>-0.711757</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>0.411614</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>-0.183699</td>\n",
       "      <td>-0.510602</td>\n",
       "      <td>1.329284</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>-1.933849</td>\n",
       "      <td>-0.962886</td>\n",
       "      <td>-1.042082</td>\n",
       "      <td>0.449624</td>\n",
       "      <td>1.962563</td>\n",
       "      <td>-0.608577</td>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>-1.040458</td>\n",
       "      <td>-0.031513</td>\n",
       "      <td>-0.188093</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2  ...       V28  Amount  Class\n",
       "0            0.0  -1.359807  -0.072781  ... -0.021053  149.62      0\n",
       "1            0.0   1.191857   0.266151  ...  0.014724    2.69      0\n",
       "2            1.0  -1.358354  -1.340163  ... -0.059752  378.66      0\n",
       "3            1.0  -0.966272  -0.185226  ...  0.061458  123.50      0\n",
       "4            2.0  -1.158233   0.877737  ...  0.215153   69.99      0\n",
       "...          ...        ...        ...  ...       ...     ...    ...\n",
       "284802  172786.0 -11.881118  10.071785  ...  0.823731    0.77      0\n",
       "284803  172787.0  -0.732789  -0.055080  ... -0.053527   24.79      0\n",
       "284804  172788.0   1.919565  -0.301254  ... -0.026561   67.88      0\n",
       "284805  172788.0  -0.240440   0.530483  ...  0.104533   10.00      0\n",
       "284806  172792.0  -0.533413  -0.189733  ...  0.013649  217.00      0\n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSWiWOmATxa7"
   },
   "source": [
    "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )**bold text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RUhzfzNL38Q",
    "outputId": "133b6ce2-d1e3-4f2a-a3a3-766b63b7d3e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      False\n",
       "V1        False\n",
       "V2        False\n",
       "V3        False\n",
       "V4        False\n",
       "V5        False\n",
       "V6        False\n",
       "V7        False\n",
       "V8        False\n",
       "V9        False\n",
       "V10       False\n",
       "V11       False\n",
       "V12       False\n",
       "V13       False\n",
       "V14       False\n",
       "V15       False\n",
       "V16       False\n",
       "V17       False\n",
       "V18       False\n",
       "V19       False\n",
       "V20       False\n",
       "V21       False\n",
       "V22       False\n",
       "V23       False\n",
       "V24       False\n",
       "V25       False\n",
       "V26       False\n",
       "V27       False\n",
       "V28       False\n",
       "Amount    False\n",
       "Class     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HGKkewyL38Q",
    "outputId": "e51e7263-1dd5-4dd6-87d5-d6eeea16d2aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(df.applymap(lambda x: x=='') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "_K0dzc1cL38Q",
    "outputId": "8eba971a-d2b9-427b-a829-1df4cc597ff2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>1.768627e-15</td>\n",
       "      <td>9.170318e-16</td>\n",
       "      <td>-1.810658e-15</td>\n",
       "      <td>1.693438e-15</td>\n",
       "      <td>1.479045e-15</td>\n",
       "      <td>3.482336e-15</td>\n",
       "      <td>1.392007e-15</td>\n",
       "      <td>-7.528491e-16</td>\n",
       "      <td>4.328772e-16</td>\n",
       "      <td>9.049732e-16</td>\n",
       "      <td>5.085503e-16</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>1.088850e+00</td>\n",
       "      <td>1.020713e+00</td>\n",
       "      <td>9.992014e-01</td>\n",
       "      <td>9.952742e-01</td>\n",
       "      <td>9.585956e-01</td>\n",
       "      <td>9.153160e-01</td>\n",
       "      <td>8.762529e-01</td>\n",
       "      <td>8.493371e-01</td>\n",
       "      <td>8.381762e-01</td>\n",
       "      <td>8.140405e-01</td>\n",
       "      <td>7.709250e-01</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>-2.458826e+01</td>\n",
       "      <td>-4.797473e+00</td>\n",
       "      <td>-1.868371e+01</td>\n",
       "      <td>-5.791881e+00</td>\n",
       "      <td>-1.921433e+01</td>\n",
       "      <td>-4.498945e+00</td>\n",
       "      <td>-1.412985e+01</td>\n",
       "      <td>-2.516280e+01</td>\n",
       "      <td>-9.498746e+00</td>\n",
       "      <td>-7.213527e+00</td>\n",
       "      <td>-5.449772e+01</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>-5.354257e-01</td>\n",
       "      <td>-7.624942e-01</td>\n",
       "      <td>-4.055715e-01</td>\n",
       "      <td>-6.485393e-01</td>\n",
       "      <td>-4.255740e-01</td>\n",
       "      <td>-5.828843e-01</td>\n",
       "      <td>-4.680368e-01</td>\n",
       "      <td>-4.837483e-01</td>\n",
       "      <td>-4.988498e-01</td>\n",
       "      <td>-4.562989e-01</td>\n",
       "      <td>-2.117214e-01</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>-9.291738e-02</td>\n",
       "      <td>-3.275735e-02</td>\n",
       "      <td>1.400326e-01</td>\n",
       "      <td>-1.356806e-02</td>\n",
       "      <td>5.060132e-02</td>\n",
       "      <td>4.807155e-02</td>\n",
       "      <td>6.641332e-02</td>\n",
       "      <td>-6.567575e-02</td>\n",
       "      <td>-3.636312e-03</td>\n",
       "      <td>3.734823e-03</td>\n",
       "      <td>-6.248109e-02</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>4.539234e-01</td>\n",
       "      <td>7.395934e-01</td>\n",
       "      <td>6.182380e-01</td>\n",
       "      <td>6.625050e-01</td>\n",
       "      <td>4.931498e-01</td>\n",
       "      <td>6.488208e-01</td>\n",
       "      <td>5.232963e-01</td>\n",
       "      <td>3.996750e-01</td>\n",
       "      <td>5.008067e-01</td>\n",
       "      <td>4.589494e-01</td>\n",
       "      <td>1.330408e-01</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>2.374514e+01</td>\n",
       "      <td>1.201891e+01</td>\n",
       "      <td>7.848392e+00</td>\n",
       "      <td>7.126883e+00</td>\n",
       "      <td>1.052677e+01</td>\n",
       "      <td>8.877742e+00</td>\n",
       "      <td>1.731511e+01</td>\n",
       "      <td>9.253526e+00</td>\n",
       "      <td>5.041069e+00</td>\n",
       "      <td>5.591971e+00</td>\n",
       "      <td>3.942090e+01</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1  ...         Amount          Class\n",
       "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
       "mean    94813.859575  3.919560e-15  ...      88.349619       0.001727\n",
       "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
       "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
       "25%     54201.500000 -9.203734e-01  ...       5.600000       0.000000\n",
       "50%     84692.000000  1.810880e-02  ...      22.000000       0.000000\n",
       "75%    139320.500000  1.315642e+00  ...      77.165000       0.000000\n",
       "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "95p2GfqQmtCw"
   },
   "outputs": [],
   "source": [
    "non_fraud = df[df['Class']==0]\n",
    "fraud = df[df['Class'] == 1]\n",
    "\n",
    "non_fraud = non_fraud.sample(fraud.shape[0])\n",
    "non_fraud.shape\n",
    "data= fraud.append(non_fraud, ignore_index=True)\n",
    "data.shape\n",
    "data['Class'].value_counts()\n",
    "x_data = data.drop(columns = 'Class', axis=0)\n",
    "label = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kpl3_4un0TMu",
    "outputId": "ff05eed3-b23d-4400-eba4-60ec8a68236b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((492, 31), (492, 31))"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud.shape, fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zPAcE8srouyp",
    "outputId": "15f8cf04-18fb-47e7-96b9-be616f9addf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1lfL8arpx7CC",
    "outputId": "2fdc4f98-7dcb-4849-e71b-e602dc40b793"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArUp-JHlUgnm"
   },
   "source": [
    "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels). Validation will be taken later during model compilation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kzPUdFD1pj4Y"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "S7SuH6okquMG"
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(x_data, label, test_size = .3, random_state=1, stratify= label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "kM4yD2OcroZQ",
    "outputId": "b49e938d-9d06-42db-fac8-155b63f95a73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>41757.0</td>\n",
       "      <td>1.039096</td>\n",
       "      <td>-0.223219</td>\n",
       "      <td>0.225559</td>\n",
       "      <td>0.465925</td>\n",
       "      <td>-0.262903</td>\n",
       "      <td>0.008269</td>\n",
       "      <td>-0.115924</td>\n",
       "      <td>0.135712</td>\n",
       "      <td>-0.016827</td>\n",
       "      <td>0.064977</td>\n",
       "      <td>1.187929</td>\n",
       "      <td>0.434258</td>\n",
       "      <td>-0.770690</td>\n",
       "      <td>0.651297</td>\n",
       "      <td>0.735649</td>\n",
       "      <td>0.333267</td>\n",
       "      <td>-0.455307</td>\n",
       "      <td>-0.076623</td>\n",
       "      <td>-0.166888</td>\n",
       "      <td>-0.002139</td>\n",
       "      <td>-0.004908</td>\n",
       "      <td>-0.224946</td>\n",
       "      <td>-0.050665</td>\n",
       "      <td>-0.310867</td>\n",
       "      <td>0.231869</td>\n",
       "      <td>0.288303</td>\n",
       "      <td>-0.039261</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>84.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>83750.0</td>\n",
       "      <td>-1.456038</td>\n",
       "      <td>0.154479</td>\n",
       "      <td>1.530177</td>\n",
       "      <td>-0.615925</td>\n",
       "      <td>-0.089024</td>\n",
       "      <td>0.166150</td>\n",
       "      <td>-1.597750</td>\n",
       "      <td>-2.437196</td>\n",
       "      <td>0.677394</td>\n",
       "      <td>-1.311095</td>\n",
       "      <td>-0.888413</td>\n",
       "      <td>0.871521</td>\n",
       "      <td>-0.100542</td>\n",
       "      <td>-0.307477</td>\n",
       "      <td>-0.823580</td>\n",
       "      <td>-0.105380</td>\n",
       "      <td>0.266654</td>\n",
       "      <td>-1.031686</td>\n",
       "      <td>-0.600748</td>\n",
       "      <td>0.253610</td>\n",
       "      <td>-1.353709</td>\n",
       "      <td>0.401608</td>\n",
       "      <td>-0.452488</td>\n",
       "      <td>0.193739</td>\n",
       "      <td>-1.283780</td>\n",
       "      <td>0.660752</td>\n",
       "      <td>0.127745</td>\n",
       "      <td>0.225786</td>\n",
       "      <td>76.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>80944.0</td>\n",
       "      <td>-0.919002</td>\n",
       "      <td>0.160646</td>\n",
       "      <td>0.744300</td>\n",
       "      <td>0.225175</td>\n",
       "      <td>-0.194467</td>\n",
       "      <td>2.305533</td>\n",
       "      <td>0.114080</td>\n",
       "      <td>1.111560</td>\n",
       "      <td>-0.492067</td>\n",
       "      <td>-0.744759</td>\n",
       "      <td>1.477011</td>\n",
       "      <td>1.112233</td>\n",
       "      <td>0.060296</td>\n",
       "      <td>0.484002</td>\n",
       "      <td>0.843833</td>\n",
       "      <td>-1.086960</td>\n",
       "      <td>0.996032</td>\n",
       "      <td>-1.286726</td>\n",
       "      <td>-0.472143</td>\n",
       "      <td>0.182283</td>\n",
       "      <td>0.408033</td>\n",
       "      <td>1.012394</td>\n",
       "      <td>0.562485</td>\n",
       "      <td>-1.303142</td>\n",
       "      <td>-1.097223</td>\n",
       "      <td>0.539341</td>\n",
       "      <td>0.066078</td>\n",
       "      <td>0.121398</td>\n",
       "      <td>190.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>142628.0</td>\n",
       "      <td>1.904325</td>\n",
       "      <td>-1.100267</td>\n",
       "      <td>-2.470284</td>\n",
       "      <td>-0.875799</td>\n",
       "      <td>0.064844</td>\n",
       "      <td>-1.195094</td>\n",
       "      <td>0.478334</td>\n",
       "      <td>-0.566902</td>\n",
       "      <td>-1.016467</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>-0.649713</td>\n",
       "      <td>-0.658616</td>\n",
       "      <td>0.191927</td>\n",
       "      <td>0.387178</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>0.457743</td>\n",
       "      <td>0.345175</td>\n",
       "      <td>-1.692878</td>\n",
       "      <td>0.577540</td>\n",
       "      <td>0.378628</td>\n",
       "      <td>0.459617</td>\n",
       "      <td>0.867415</td>\n",
       "      <td>-0.216171</td>\n",
       "      <td>0.679004</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.035308</td>\n",
       "      <td>-0.117619</td>\n",
       "      <td>-0.041267</td>\n",
       "      <td>210.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>118532.0</td>\n",
       "      <td>-5.961457</td>\n",
       "      <td>5.313382</td>\n",
       "      <td>-6.674320</td>\n",
       "      <td>6.028975</td>\n",
       "      <td>-1.387560</td>\n",
       "      <td>0.670638</td>\n",
       "      <td>-4.128987</td>\n",
       "      <td>-4.765894</td>\n",
       "      <td>-1.005259</td>\n",
       "      <td>0.453505</td>\n",
       "      <td>4.431736</td>\n",
       "      <td>-5.142737</td>\n",
       "      <td>-1.181692</td>\n",
       "      <td>-8.755449</td>\n",
       "      <td>1.004356</td>\n",
       "      <td>-2.065026</td>\n",
       "      <td>-3.261435</td>\n",
       "      <td>0.125223</td>\n",
       "      <td>0.936966</td>\n",
       "      <td>-1.116581</td>\n",
       "      <td>5.556642</td>\n",
       "      <td>-1.501808</td>\n",
       "      <td>1.355172</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.077913</td>\n",
       "      <td>0.473988</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>1.468653</td>\n",
       "      <td>105.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>46372.0</td>\n",
       "      <td>-0.604026</td>\n",
       "      <td>1.257194</td>\n",
       "      <td>1.077036</td>\n",
       "      <td>-0.155965</td>\n",
       "      <td>0.160228</td>\n",
       "      <td>-0.315266</td>\n",
       "      <td>0.308289</td>\n",
       "      <td>-0.670518</td>\n",
       "      <td>-0.519710</td>\n",
       "      <td>-0.262276</td>\n",
       "      <td>1.135031</td>\n",
       "      <td>0.405561</td>\n",
       "      <td>-0.228503</td>\n",
       "      <td>-0.166768</td>\n",
       "      <td>0.232697</td>\n",
       "      <td>0.694290</td>\n",
       "      <td>-0.281026</td>\n",
       "      <td>0.513305</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>-0.052355</td>\n",
       "      <td>0.525005</td>\n",
       "      <td>-0.921860</td>\n",
       "      <td>0.045234</td>\n",
       "      <td>-0.070367</td>\n",
       "      <td>-0.138603</td>\n",
       "      <td>0.082119</td>\n",
       "      <td>0.275781</td>\n",
       "      <td>0.091388</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>96291.0</td>\n",
       "      <td>-3.552173</td>\n",
       "      <td>5.426461</td>\n",
       "      <td>-3.731810</td>\n",
       "      <td>6.679062</td>\n",
       "      <td>-2.187543</td>\n",
       "      <td>2.433940</td>\n",
       "      <td>-8.748110</td>\n",
       "      <td>-12.108284</td>\n",
       "      <td>-2.856359</td>\n",
       "      <td>-5.665862</td>\n",
       "      <td>2.540836</td>\n",
       "      <td>-6.147054</td>\n",
       "      <td>1.796891</td>\n",
       "      <td>-4.328989</td>\n",
       "      <td>-0.150037</td>\n",
       "      <td>-1.839005</td>\n",
       "      <td>-3.354638</td>\n",
       "      <td>-0.282307</td>\n",
       "      <td>0.148592</td>\n",
       "      <td>3.792667</td>\n",
       "      <td>-5.688990</td>\n",
       "      <td>2.510980</td>\n",
       "      <td>0.953933</td>\n",
       "      <td>-0.542506</td>\n",
       "      <td>-0.620152</td>\n",
       "      <td>0.406013</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>0.164741</td>\n",
       "      <td>33.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>143603.0</td>\n",
       "      <td>2.032448</td>\n",
       "      <td>-0.022721</td>\n",
       "      <td>-1.429822</td>\n",
       "      <td>0.132413</td>\n",
       "      <td>0.351459</td>\n",
       "      <td>-0.541265</td>\n",
       "      <td>0.121327</td>\n",
       "      <td>-0.170956</td>\n",
       "      <td>0.236004</td>\n",
       "      <td>0.152011</td>\n",
       "      <td>1.155672</td>\n",
       "      <td>1.272293</td>\n",
       "      <td>0.556026</td>\n",
       "      <td>0.564521</td>\n",
       "      <td>0.068081</td>\n",
       "      <td>-0.085251</td>\n",
       "      <td>-0.744407</td>\n",
       "      <td>0.300096</td>\n",
       "      <td>-0.015483</td>\n",
       "      <td>-0.176510</td>\n",
       "      <td>0.304590</td>\n",
       "      <td>1.006161</td>\n",
       "      <td>0.027098</td>\n",
       "      <td>0.756044</td>\n",
       "      <td>0.257735</td>\n",
       "      <td>-0.160604</td>\n",
       "      <td>-0.021378</td>\n",
       "      <td>-0.060979</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>120409.0</td>\n",
       "      <td>2.322645</td>\n",
       "      <td>-1.319286</td>\n",
       "      <td>-1.176087</td>\n",
       "      <td>-1.636639</td>\n",
       "      <td>-0.953380</td>\n",
       "      <td>-0.501694</td>\n",
       "      <td>-1.023974</td>\n",
       "      <td>-0.211787</td>\n",
       "      <td>-1.256796</td>\n",
       "      <td>1.567143</td>\n",
       "      <td>-1.259266</td>\n",
       "      <td>-0.818917</td>\n",
       "      <td>0.664997</td>\n",
       "      <td>-0.458351</td>\n",
       "      <td>-0.177840</td>\n",
       "      <td>-0.523987</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>-0.042984</td>\n",
       "      <td>-0.007888</td>\n",
       "      <td>-0.384563</td>\n",
       "      <td>-0.189574</td>\n",
       "      <td>-0.053785</td>\n",
       "      <td>0.220719</td>\n",
       "      <td>0.460840</td>\n",
       "      <td>-0.103371</td>\n",
       "      <td>-0.179131</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>-0.046105</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>145926.0</td>\n",
       "      <td>1.748650</td>\n",
       "      <td>-1.119045</td>\n",
       "      <td>0.689982</td>\n",
       "      <td>0.784760</td>\n",
       "      <td>-1.377449</td>\n",
       "      <td>1.050373</td>\n",
       "      <td>-1.518323</td>\n",
       "      <td>0.484449</td>\n",
       "      <td>2.450615</td>\n",
       "      <td>-0.380646</td>\n",
       "      <td>-0.226485</td>\n",
       "      <td>1.821015</td>\n",
       "      <td>0.444606</td>\n",
       "      <td>-1.184127</td>\n",
       "      <td>-2.070701</td>\n",
       "      <td>-0.189633</td>\n",
       "      <td>-0.265113</td>\n",
       "      <td>0.578338</td>\n",
       "      <td>0.553440</td>\n",
       "      <td>-0.098673</td>\n",
       "      <td>0.179641</td>\n",
       "      <td>1.015895</td>\n",
       "      <td>0.029459</td>\n",
       "      <td>-0.322746</td>\n",
       "      <td>-0.183990</td>\n",
       "      <td>-0.157482</td>\n",
       "      <td>0.105047</td>\n",
       "      <td>-0.028253</td>\n",
       "      <td>59.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time        V1        V2  ...       V27       V28  Amount\n",
       "902   41757.0  1.039096 -0.223219  ... -0.039261  0.011227   84.50\n",
       "747   83750.0 -1.456038  0.154479  ...  0.127745  0.225786   76.61\n",
       "701   80944.0 -0.919002  0.160646  ...  0.066078  0.121398  190.32\n",
       "827  142628.0  1.904325 -1.100267  ... -0.117619 -0.041267  210.18\n",
       "358  118532.0 -5.961457  5.313382  ...  0.287129  1.468653  105.89\n",
       "..        ...       ...       ...  ...       ...       ...     ...\n",
       "695   46372.0 -0.604026  1.257194  ...  0.275781  0.091388    2.69\n",
       "326   96291.0 -3.552173  5.426461  ...  0.023025  0.164741   33.59\n",
       "578  143603.0  2.032448 -0.022721  ... -0.021378 -0.060979    0.89\n",
       "934  120409.0  2.322645 -1.319286  ...  0.003885 -0.046105   20.00\n",
       "923  145926.0  1.748650 -1.119045  ...  0.105047 -0.028253   59.29\n",
       "\n",
       "[296 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlN-oj-pL38Q",
    "outputId": "ec8ec4c9-63d8-4844-ae18-7f53250c5dd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1825"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = np.where(df.Amount.apply(lambda x: x == 0))\n",
    "(df['Amount'].values == 0 ).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "XQ8PRMUDL38R",
    "outputId": "ac69a283-2103-479f-ee46-eb7986e5e068"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>166883.0</td>\n",
       "      <td>2.091900</td>\n",
       "      <td>-0.757459</td>\n",
       "      <td>-1.192258</td>\n",
       "      <td>-0.755458</td>\n",
       "      <td>-0.620324</td>\n",
       "      <td>-0.322077</td>\n",
       "      <td>-1.082511</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>-0.140927</td>\n",
       "      <td>0.249311</td>\n",
       "      <td>1.338318</td>\n",
       "      <td>-0.329759</td>\n",
       "      <td>-0.363591</td>\n",
       "      <td>-1.824839</td>\n",
       "      <td>-0.229679</td>\n",
       "      <td>1.842347</td>\n",
       "      <td>1.194212</td>\n",
       "      <td>0.037467</td>\n",
       "      <td>0.423099</td>\n",
       "      <td>0.037438</td>\n",
       "      <td>0.288253</td>\n",
       "      <td>0.831939</td>\n",
       "      <td>0.142007</td>\n",
       "      <td>0.592615</td>\n",
       "      <td>-0.196143</td>\n",
       "      <td>-0.136676</td>\n",
       "      <td>0.020182</td>\n",
       "      <td>-0.015470</td>\n",
       "      <td>19.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>126982.0</td>\n",
       "      <td>-1.026473</td>\n",
       "      <td>0.050271</td>\n",
       "      <td>1.127993</td>\n",
       "      <td>-2.911860</td>\n",
       "      <td>-0.806451</td>\n",
       "      <td>-0.958943</td>\n",
       "      <td>-0.165125</td>\n",
       "      <td>0.137558</td>\n",
       "      <td>-2.574707</td>\n",
       "      <td>0.269533</td>\n",
       "      <td>-1.159428</td>\n",
       "      <td>-0.518514</td>\n",
       "      <td>1.325742</td>\n",
       "      <td>-0.459310</td>\n",
       "      <td>-0.957093</td>\n",
       "      <td>-0.402401</td>\n",
       "      <td>0.418270</td>\n",
       "      <td>-0.164337</td>\n",
       "      <td>-0.682555</td>\n",
       "      <td>-0.437094</td>\n",
       "      <td>-0.104615</td>\n",
       "      <td>-0.045878</td>\n",
       "      <td>-0.336513</td>\n",
       "      <td>0.055066</td>\n",
       "      <td>0.763125</td>\n",
       "      <td>-0.136629</td>\n",
       "      <td>-0.226534</td>\n",
       "      <td>-0.027085</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>25231.0</td>\n",
       "      <td>-16.598665</td>\n",
       "      <td>10.541751</td>\n",
       "      <td>-19.818982</td>\n",
       "      <td>6.017295</td>\n",
       "      <td>-13.025901</td>\n",
       "      <td>-4.128779</td>\n",
       "      <td>-14.118865</td>\n",
       "      <td>11.161144</td>\n",
       "      <td>-4.099551</td>\n",
       "      <td>-9.222826</td>\n",
       "      <td>6.329365</td>\n",
       "      <td>-8.952191</td>\n",
       "      <td>-0.138364</td>\n",
       "      <td>-9.825054</td>\n",
       "      <td>0.057224</td>\n",
       "      <td>-7.541687</td>\n",
       "      <td>-14.259599</td>\n",
       "      <td>-5.035052</td>\n",
       "      <td>1.432268</td>\n",
       "      <td>1.534920</td>\n",
       "      <td>1.725853</td>\n",
       "      <td>-1.151606</td>\n",
       "      <td>-0.680052</td>\n",
       "      <td>0.108176</td>\n",
       "      <td>1.066878</td>\n",
       "      <td>-0.233720</td>\n",
       "      <td>1.707521</td>\n",
       "      <td>0.511423</td>\n",
       "      <td>99.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>41170.0</td>\n",
       "      <td>-6.498086</td>\n",
       "      <td>4.750515</td>\n",
       "      <td>-8.966558</td>\n",
       "      <td>7.098854</td>\n",
       "      <td>-6.958376</td>\n",
       "      <td>-2.822126</td>\n",
       "      <td>-10.333406</td>\n",
       "      <td>4.031907</td>\n",
       "      <td>-6.648778</td>\n",
       "      <td>-11.634414</td>\n",
       "      <td>6.877571</td>\n",
       "      <td>-13.697686</td>\n",
       "      <td>0.463040</td>\n",
       "      <td>-13.044182</td>\n",
       "      <td>-0.309229</td>\n",
       "      <td>-12.317580</td>\n",
       "      <td>-24.019099</td>\n",
       "      <td>-9.335193</td>\n",
       "      <td>1.951890</td>\n",
       "      <td>0.568338</td>\n",
       "      <td>2.158143</td>\n",
       "      <td>0.111510</td>\n",
       "      <td>0.216414</td>\n",
       "      <td>0.584661</td>\n",
       "      <td>0.760360</td>\n",
       "      <td>0.081972</td>\n",
       "      <td>1.415068</td>\n",
       "      <td>0.035124</td>\n",
       "      <td>83.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>37027.0</td>\n",
       "      <td>1.177536</td>\n",
       "      <td>-0.180911</td>\n",
       "      <td>0.467235</td>\n",
       "      <td>-0.041377</td>\n",
       "      <td>-0.370506</td>\n",
       "      <td>-0.060037</td>\n",
       "      <td>-0.301914</td>\n",
       "      <td>-0.031368</td>\n",
       "      <td>0.282076</td>\n",
       "      <td>-0.246357</td>\n",
       "      <td>-0.341170</td>\n",
       "      <td>0.746889</td>\n",
       "      <td>1.543150</td>\n",
       "      <td>-0.217667</td>\n",
       "      <td>1.468916</td>\n",
       "      <td>0.323549</td>\n",
       "      <td>-0.429235</td>\n",
       "      <td>-0.545867</td>\n",
       "      <td>-0.374862</td>\n",
       "      <td>0.097295</td>\n",
       "      <td>0.110659</td>\n",
       "      <td>0.360932</td>\n",
       "      <td>-0.107570</td>\n",
       "      <td>-0.336131</td>\n",
       "      <td>0.261836</td>\n",
       "      <td>1.124516</td>\n",
       "      <td>-0.044412</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>47.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time         V1         V2  ...       V27       V28  Amount\n",
       "485  166883.0   2.091900  -0.757459  ...  0.020182 -0.015470   19.95\n",
       "812  126982.0  -1.026473   0.050271  ... -0.226534 -0.027085   15.00\n",
       "58    25231.0 -16.598665  10.541751  ...  1.707521  0.511423   99.99\n",
       "115   41170.0  -6.498086   4.750515  ...  1.415068  0.035124   83.38\n",
       "763   37027.0   1.177536  -0.180911  ... -0.044412  0.011853   47.85\n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "ctZhhrzJRrE8",
    "outputId": "1047edfe-8686-4514-cf2b-1d7c6c5c395e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>41757.0</td>\n",
       "      <td>1.039096</td>\n",
       "      <td>-0.223219</td>\n",
       "      <td>0.225559</td>\n",
       "      <td>0.465925</td>\n",
       "      <td>-0.262903</td>\n",
       "      <td>0.008269</td>\n",
       "      <td>-0.115924</td>\n",
       "      <td>0.135712</td>\n",
       "      <td>-0.016827</td>\n",
       "      <td>0.064977</td>\n",
       "      <td>1.187929</td>\n",
       "      <td>0.434258</td>\n",
       "      <td>-0.770690</td>\n",
       "      <td>0.651297</td>\n",
       "      <td>0.735649</td>\n",
       "      <td>0.333267</td>\n",
       "      <td>-0.455307</td>\n",
       "      <td>-0.076623</td>\n",
       "      <td>-0.166888</td>\n",
       "      <td>-0.002139</td>\n",
       "      <td>-0.004908</td>\n",
       "      <td>-0.224946</td>\n",
       "      <td>-0.050665</td>\n",
       "      <td>-0.310867</td>\n",
       "      <td>0.231869</td>\n",
       "      <td>0.288303</td>\n",
       "      <td>-0.039261</td>\n",
       "      <td>0.011227</td>\n",
       "      <td>84.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>83750.0</td>\n",
       "      <td>-1.456038</td>\n",
       "      <td>0.154479</td>\n",
       "      <td>1.530177</td>\n",
       "      <td>-0.615925</td>\n",
       "      <td>-0.089024</td>\n",
       "      <td>0.166150</td>\n",
       "      <td>-1.597750</td>\n",
       "      <td>-2.437196</td>\n",
       "      <td>0.677394</td>\n",
       "      <td>-1.311095</td>\n",
       "      <td>-0.888413</td>\n",
       "      <td>0.871521</td>\n",
       "      <td>-0.100542</td>\n",
       "      <td>-0.307477</td>\n",
       "      <td>-0.823580</td>\n",
       "      <td>-0.105380</td>\n",
       "      <td>0.266654</td>\n",
       "      <td>-1.031686</td>\n",
       "      <td>-0.600748</td>\n",
       "      <td>0.253610</td>\n",
       "      <td>-1.353709</td>\n",
       "      <td>0.401608</td>\n",
       "      <td>-0.452488</td>\n",
       "      <td>0.193739</td>\n",
       "      <td>-1.283780</td>\n",
       "      <td>0.660752</td>\n",
       "      <td>0.127745</td>\n",
       "      <td>0.225786</td>\n",
       "      <td>76.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>80944.0</td>\n",
       "      <td>-0.919002</td>\n",
       "      <td>0.160646</td>\n",
       "      <td>0.744300</td>\n",
       "      <td>0.225175</td>\n",
       "      <td>-0.194467</td>\n",
       "      <td>2.305533</td>\n",
       "      <td>0.114080</td>\n",
       "      <td>1.111560</td>\n",
       "      <td>-0.492067</td>\n",
       "      <td>-0.744759</td>\n",
       "      <td>1.477011</td>\n",
       "      <td>1.112233</td>\n",
       "      <td>0.060296</td>\n",
       "      <td>0.484002</td>\n",
       "      <td>0.843833</td>\n",
       "      <td>-1.086960</td>\n",
       "      <td>0.996032</td>\n",
       "      <td>-1.286726</td>\n",
       "      <td>-0.472143</td>\n",
       "      <td>0.182283</td>\n",
       "      <td>0.408033</td>\n",
       "      <td>1.012394</td>\n",
       "      <td>0.562485</td>\n",
       "      <td>-1.303142</td>\n",
       "      <td>-1.097223</td>\n",
       "      <td>0.539341</td>\n",
       "      <td>0.066078</td>\n",
       "      <td>0.121398</td>\n",
       "      <td>190.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>142628.0</td>\n",
       "      <td>1.904325</td>\n",
       "      <td>-1.100267</td>\n",
       "      <td>-2.470284</td>\n",
       "      <td>-0.875799</td>\n",
       "      <td>0.064844</td>\n",
       "      <td>-1.195094</td>\n",
       "      <td>0.478334</td>\n",
       "      <td>-0.566902</td>\n",
       "      <td>-1.016467</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>-0.649713</td>\n",
       "      <td>-0.658616</td>\n",
       "      <td>0.191927</td>\n",
       "      <td>0.387178</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>0.457743</td>\n",
       "      <td>0.345175</td>\n",
       "      <td>-1.692878</td>\n",
       "      <td>0.577540</td>\n",
       "      <td>0.378628</td>\n",
       "      <td>0.459617</td>\n",
       "      <td>0.867415</td>\n",
       "      <td>-0.216171</td>\n",
       "      <td>0.679004</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.035308</td>\n",
       "      <td>-0.117619</td>\n",
       "      <td>-0.041267</td>\n",
       "      <td>210.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>118532.0</td>\n",
       "      <td>-5.961457</td>\n",
       "      <td>5.313382</td>\n",
       "      <td>-6.674320</td>\n",
       "      <td>6.028975</td>\n",
       "      <td>-1.387560</td>\n",
       "      <td>0.670638</td>\n",
       "      <td>-4.128987</td>\n",
       "      <td>-4.765894</td>\n",
       "      <td>-1.005259</td>\n",
       "      <td>0.453505</td>\n",
       "      <td>4.431736</td>\n",
       "      <td>-5.142737</td>\n",
       "      <td>-1.181692</td>\n",
       "      <td>-8.755449</td>\n",
       "      <td>1.004356</td>\n",
       "      <td>-2.065026</td>\n",
       "      <td>-3.261435</td>\n",
       "      <td>0.125223</td>\n",
       "      <td>0.936966</td>\n",
       "      <td>-1.116581</td>\n",
       "      <td>5.556642</td>\n",
       "      <td>-1.501808</td>\n",
       "      <td>1.355172</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.077913</td>\n",
       "      <td>0.473988</td>\n",
       "      <td>0.287129</td>\n",
       "      <td>1.468653</td>\n",
       "      <td>105.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time        V1        V2  ...       V27       V28  Amount\n",
       "902   41757.0  1.039096 -0.223219  ... -0.039261  0.011227   84.50\n",
       "747   83750.0 -1.456038  0.154479  ...  0.127745  0.225786   76.61\n",
       "701   80944.0 -0.919002  0.160646  ...  0.066078  0.121398  190.32\n",
       "827  142628.0  1.904325 -1.100267  ... -0.117619 -0.041267  210.18\n",
       "358  118532.0 -5.961457  5.313382  ...  0.287129  1.468653  105.89\n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcN-SihOUCmn"
   },
   "source": [
    "**3.Standardized the Input Variables. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "PTvvVyX4Rxoq"
   },
   "outputs": [],
   "source": [
    "mean =  train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /=std\n",
    "test_data -=mean\n",
    "test_data /=std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cox_sC5RSFwI",
    "outputId": "09232f09-81e9-45c7-eec4-2f607101364d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUleqHbrVcky"
   },
   "source": [
    "\n",
    "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cGXiO6M1SIYx"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-1-6c18982f0347>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-6c18982f0347>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    model.add(layers.Dense(1)\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(10, activation= 'relu',input_shape=(train_data.shape[1],)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(8, activation= 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(6, activation= 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(1, activation= 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iWYk07Lf24it"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2ac054dd5e91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model1 = models.Sequential()\n",
    "model1.add(layers.Dense(10, activation= 'tanh',input_shape=(train_data.shape[1],)))\n",
    "model1.add(layers.Dropout(0.3))\n",
    "model1.add(layers.Dense(8, activation= 'tanh'))\n",
    "model1.add(layers.Dropout(0.3))\n",
    "model1.add(layers.Dense(6, activation= 'tanh'))\n",
    "model1.add(layers.Dropout(0.3))\n",
    "model1.add(layers.Dense(1, activation= 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "k_Q4UvMkT5jf"
   },
   "outputs": [],
   "source": [
    "model.compile(loss ='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0r72skzVU1v"
   },
   "source": [
    "7.Train the Model with Epochs (100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymHJhVlpU-Ci",
    "outputId": "2daa1d8f-522d-406f-90ad-4e62ec53c945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.2287 - accuracy: 0.9314 - val_loss: 0.1575 - val_accuracy: 0.9420\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2190 - accuracy: 0.9397 - val_loss: 0.1575 - val_accuracy: 0.9420\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2186 - accuracy: 0.9272 - val_loss: 0.1557 - val_accuracy: 0.9420\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2055 - accuracy: 0.9356 - val_loss: 0.1547 - val_accuracy: 0.9420\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1896 - accuracy: 0.9480 - val_loss: 0.1547 - val_accuracy: 0.9420\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1842 - accuracy: 0.9418 - val_loss: 0.1559 - val_accuracy: 0.9517\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1771 - accuracy: 0.9439 - val_loss: 0.1534 - val_accuracy: 0.9517\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1985 - accuracy: 0.9418 - val_loss: 0.1535 - val_accuracy: 0.9517\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1826 - accuracy: 0.9480 - val_loss: 0.1529 - val_accuracy: 0.9517\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2119 - accuracy: 0.9335 - val_loss: 0.1547 - val_accuracy: 0.9517\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2406 - accuracy: 0.9356 - val_loss: 0.1567 - val_accuracy: 0.9517\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1820 - accuracy: 0.9501 - val_loss: 0.1543 - val_accuracy: 0.9517\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2010 - accuracy: 0.9272 - val_loss: 0.1532 - val_accuracy: 0.9517\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1723 - accuracy: 0.9501 - val_loss: 0.1532 - val_accuracy: 0.9517\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2036 - accuracy: 0.9418 - val_loss: 0.1525 - val_accuracy: 0.9517\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.9418 - val_loss: 0.1503 - val_accuracy: 0.9565\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1875 - accuracy: 0.9418 - val_loss: 0.1517 - val_accuracy: 0.9614\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1680 - accuracy: 0.9584 - val_loss: 0.1532 - val_accuracy: 0.9517\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9376 - val_loss: 0.1537 - val_accuracy: 0.9565\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.9459 - val_loss: 0.1538 - val_accuracy: 0.9517\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1775 - accuracy: 0.9459 - val_loss: 0.1513 - val_accuracy: 0.9614\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1748 - accuracy: 0.9397 - val_loss: 0.1515 - val_accuracy: 0.9469\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1674 - accuracy: 0.9584 - val_loss: 0.1527 - val_accuracy: 0.9614\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2031 - accuracy: 0.9418 - val_loss: 0.1537 - val_accuracy: 0.9565\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1966 - accuracy: 0.9439 - val_loss: 0.1529 - val_accuracy: 0.9565\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1673 - accuracy: 0.9501 - val_loss: 0.1507 - val_accuracy: 0.9565\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1807 - accuracy: 0.9480 - val_loss: 0.1512 - val_accuracy: 0.9614\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2102 - accuracy: 0.9293 - val_loss: 0.1501 - val_accuracy: 0.9565\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1835 - accuracy: 0.9459 - val_loss: 0.1501 - val_accuracy: 0.9614\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1954 - accuracy: 0.9418 - val_loss: 0.1491 - val_accuracy: 0.9614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4a9b9ef7d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, epochs=30, validation_split= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "db6xtp_eStno"
   },
   "outputs": [],
   "source": [
    "model1.compile(loss ='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZLwLr3FSz8f",
    "outputId": "fd7449de-4259-4b98-aaab-20f26e2b4d87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3299 - accuracy: 0.8773 - val_loss: 0.2101 - val_accuracy: 0.9372\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3087 - accuracy: 0.8940 - val_loss: 0.2049 - val_accuracy: 0.9420\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3227 - accuracy: 0.8877 - val_loss: 0.2018 - val_accuracy: 0.9420\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2853 - accuracy: 0.9002 - val_loss: 0.1988 - val_accuracy: 0.9420\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2982 - accuracy: 0.9002 - val_loss: 0.1942 - val_accuracy: 0.9420\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2878 - accuracy: 0.9106 - val_loss: 0.1937 - val_accuracy: 0.9420\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2782 - accuracy: 0.9023 - val_loss: 0.1903 - val_accuracy: 0.9420\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2852 - accuracy: 0.8857 - val_loss: 0.1887 - val_accuracy: 0.9420\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2847 - accuracy: 0.8981 - val_loss: 0.1849 - val_accuracy: 0.9420\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2870 - accuracy: 0.9044 - val_loss: 0.1839 - val_accuracy: 0.9420\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2601 - accuracy: 0.9148 - val_loss: 0.1814 - val_accuracy: 0.9420\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2678 - accuracy: 0.9064 - val_loss: 0.1794 - val_accuracy: 0.9469\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2758 - accuracy: 0.9064 - val_loss: 0.1791 - val_accuracy: 0.9420\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2650 - accuracy: 0.9148 - val_loss: 0.1779 - val_accuracy: 0.9420\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.9085 - val_loss: 0.1768 - val_accuracy: 0.9372\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2550 - accuracy: 0.9168 - val_loss: 0.1752 - val_accuracy: 0.9372\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2757 - accuracy: 0.9044 - val_loss: 0.1712 - val_accuracy: 0.9469\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2421 - accuracy: 0.9168 - val_loss: 0.1737 - val_accuracy: 0.9469\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2561 - accuracy: 0.9189 - val_loss: 0.1709 - val_accuracy: 0.9420\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2440 - accuracy: 0.9210 - val_loss: 0.1684 - val_accuracy: 0.9469\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2267 - accuracy: 0.9314 - val_loss: 0.1670 - val_accuracy: 0.9420\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2292 - accuracy: 0.9252 - val_loss: 0.1698 - val_accuracy: 0.9420\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2310 - accuracy: 0.9356 - val_loss: 0.1679 - val_accuracy: 0.9420\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2429 - accuracy: 0.9189 - val_loss: 0.1661 - val_accuracy: 0.9420\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2241 - accuracy: 0.9314 - val_loss: 0.1651 - val_accuracy: 0.9420\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2534 - accuracy: 0.9189 - val_loss: 0.1628 - val_accuracy: 0.9420\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2450 - accuracy: 0.9168 - val_loss: 0.1640 - val_accuracy: 0.9420\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2059 - accuracy: 0.9314 - val_loss: 0.1672 - val_accuracy: 0.9420\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2114 - accuracy: 0.9293 - val_loss: 0.1636 - val_accuracy: 0.9420\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2280 - accuracy: 0.9252 - val_loss: 0.1585 - val_accuracy: 0.9469\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2209 - accuracy: 0.9293 - val_loss: 0.1604 - val_accuracy: 0.9469\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2185 - accuracy: 0.9376 - val_loss: 0.1601 - val_accuracy: 0.9469\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2291 - accuracy: 0.9252 - val_loss: 0.1602 - val_accuracy: 0.9469\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2335 - accuracy: 0.9314 - val_loss: 0.1587 - val_accuracy: 0.9517\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2375 - accuracy: 0.9252 - val_loss: 0.1609 - val_accuracy: 0.9469\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2101 - accuracy: 0.9376 - val_loss: 0.1614 - val_accuracy: 0.9517\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1994 - accuracy: 0.9231 - val_loss: 0.1611 - val_accuracy: 0.9469\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2332 - accuracy: 0.9231 - val_loss: 0.1588 - val_accuracy: 0.9517\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2148 - accuracy: 0.9376 - val_loss: 0.1587 - val_accuracy: 0.9517\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.9272 - val_loss: 0.1547 - val_accuracy: 0.9517\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2158 - accuracy: 0.9314 - val_loss: 0.1544 - val_accuracy: 0.9517\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2054 - accuracy: 0.9356 - val_loss: 0.1571 - val_accuracy: 0.9517\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2010 - accuracy: 0.9397 - val_loss: 0.1539 - val_accuracy: 0.9517\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2086 - accuracy: 0.9335 - val_loss: 0.1557 - val_accuracy: 0.9517\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2137 - accuracy: 0.9293 - val_loss: 0.1563 - val_accuracy: 0.9517\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2011 - accuracy: 0.9459 - val_loss: 0.1555 - val_accuracy: 0.9517\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1976 - accuracy: 0.9418 - val_loss: 0.1550 - val_accuracy: 0.9517\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2286 - accuracy: 0.9148 - val_loss: 0.1543 - val_accuracy: 0.9517\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2140 - accuracy: 0.9272 - val_loss: 0.1533 - val_accuracy: 0.9517\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2262 - accuracy: 0.9252 - val_loss: 0.1514 - val_accuracy: 0.9517\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2129 - accuracy: 0.9335 - val_loss: 0.1535 - val_accuracy: 0.9517\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2187 - accuracy: 0.9272 - val_loss: 0.1524 - val_accuracy: 0.9517\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2170 - accuracy: 0.9314 - val_loss: 0.1524 - val_accuracy: 0.9517\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1864 - accuracy: 0.9459 - val_loss: 0.1517 - val_accuracy: 0.9517\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9293 - val_loss: 0.1519 - val_accuracy: 0.9517\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2133 - accuracy: 0.9376 - val_loss: 0.1508 - val_accuracy: 0.9517\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2134 - accuracy: 0.9293 - val_loss: 0.1512 - val_accuracy: 0.9517\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2157 - accuracy: 0.9272 - val_loss: 0.1522 - val_accuracy: 0.9517\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2060 - accuracy: 0.9335 - val_loss: 0.1513 - val_accuracy: 0.9517\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1803 - accuracy: 0.9418 - val_loss: 0.1534 - val_accuracy: 0.9517\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2140 - accuracy: 0.9376 - val_loss: 0.1520 - val_accuracy: 0.9517\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1753 - accuracy: 0.9480 - val_loss: 0.1506 - val_accuracy: 0.9517\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2037 - accuracy: 0.9335 - val_loss: 0.1528 - val_accuracy: 0.9517\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2093 - accuracy: 0.9335 - val_loss: 0.1524 - val_accuracy: 0.9517\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1953 - accuracy: 0.9418 - val_loss: 0.1537 - val_accuracy: 0.9517\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2007 - accuracy: 0.9418 - val_loss: 0.1538 - val_accuracy: 0.9517\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.9335 - val_loss: 0.1551 - val_accuracy: 0.9517\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1751 - accuracy: 0.9439 - val_loss: 0.1559 - val_accuracy: 0.9517\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2060 - accuracy: 0.9335 - val_loss: 0.1553 - val_accuracy: 0.9517\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1805 - accuracy: 0.9418 - val_loss: 0.1568 - val_accuracy: 0.9517\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1986 - accuracy: 0.9335 - val_loss: 0.1533 - val_accuracy: 0.9517\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2043 - accuracy: 0.9335 - val_loss: 0.1535 - val_accuracy: 0.9517\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1911 - accuracy: 0.9356 - val_loss: 0.1557 - val_accuracy: 0.9517\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1864 - accuracy: 0.9439 - val_loss: 0.1530 - val_accuracy: 0.9517\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2161 - accuracy: 0.9314 - val_loss: 0.1520 - val_accuracy: 0.9517\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1904 - accuracy: 0.9480 - val_loss: 0.1527 - val_accuracy: 0.9517\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.9397 - val_loss: 0.1545 - val_accuracy: 0.9517\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1904 - accuracy: 0.9376 - val_loss: 0.1524 - val_accuracy: 0.9517\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1745 - accuracy: 0.9501 - val_loss: 0.1490 - val_accuracy: 0.9517\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1913 - accuracy: 0.9397 - val_loss: 0.1480 - val_accuracy: 0.9517\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1822 - accuracy: 0.9397 - val_loss: 0.1538 - val_accuracy: 0.9517\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1964 - accuracy: 0.9335 - val_loss: 0.1518 - val_accuracy: 0.9517\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1745 - accuracy: 0.9418 - val_loss: 0.1521 - val_accuracy: 0.9517\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1903 - accuracy: 0.9356 - val_loss: 0.1499 - val_accuracy: 0.9517\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1944 - accuracy: 0.9439 - val_loss: 0.1541 - val_accuracy: 0.9517\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1941 - accuracy: 0.9439 - val_loss: 0.1552 - val_accuracy: 0.9517\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1997 - accuracy: 0.9459 - val_loss: 0.1522 - val_accuracy: 0.9517\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1618 - accuracy: 0.9480 - val_loss: 0.1475 - val_accuracy: 0.9517\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1939 - accuracy: 0.9335 - val_loss: 0.1472 - val_accuracy: 0.9517\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2026 - accuracy: 0.9272 - val_loss: 0.1493 - val_accuracy: 0.9517\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1900 - accuracy: 0.9418 - val_loss: 0.1452 - val_accuracy: 0.9517\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2152 - accuracy: 0.9293 - val_loss: 0.1451 - val_accuracy: 0.9517\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2003 - accuracy: 0.9439 - val_loss: 0.1459 - val_accuracy: 0.9517\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1836 - accuracy: 0.9439 - val_loss: 0.1448 - val_accuracy: 0.9517\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1963 - accuracy: 0.9314 - val_loss: 0.1451 - val_accuracy: 0.9517\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1952 - accuracy: 0.9356 - val_loss: 0.1477 - val_accuracy: 0.9517\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1675 - accuracy: 0.9522 - val_loss: 0.1466 - val_accuracy: 0.9517\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1859 - accuracy: 0.9376 - val_loss: 0.1487 - val_accuracy: 0.9517\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1825 - accuracy: 0.9376 - val_loss: 0.1481 - val_accuracy: 0.9517\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2100 - accuracy: 0.9397 - val_loss: 0.1494 - val_accuracy: 0.9517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4a9bfae6d0>"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train_data, train_labels, epochs=100, validation_split= 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUn87UeQV5QY"
   },
   "source": [
    "9.Prediction should be > 92%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKCrqZiggD1n",
    "outputId": "f85618d0-a04c-4b94-bce5-4f6f1619766b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9459\n"
     ]
    }
   ],
   "source": [
    "test_loss_Score1, test_acc_score1 = model1.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3dKcEnvPlSN",
    "outputId": "99bc02b6-0abc-468d-9159-c8d47b1503ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1704 - accuracy: 0.9493\n"
     ]
    }
   ],
   "source": [
    "test_loss_Score, test_acc_score = model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dXNlYIpP08f",
    "outputId": "1626e4cf-bc37-490b-80de-e725454dc3cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.93243098258972"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_score*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMg1sKSNWCgV"
   },
   "source": [
    "10.Evaluation Step 11Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHXXZy8Xgdca",
    "outputId": "baba34a2-b5ef-4cc9-e6c6-a20416f45f30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07554892]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(test_data.iloc[1,:]).reshape(1,test_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "AnYfzilWzJwy"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_data).astype(dtype='u8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IStEw_HzRIfp",
    "outputId": "36ec9a0e-c876-41c2-e931-3ae632d407e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=uint64)"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9THOBPnMzo-G",
    "outputId": "23974d54-bbc3-415f-9d23-7fcda8929294"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902    0\n",
       "747    0\n",
       "701    0\n",
       "827    0\n",
       "358    1\n",
       "794    0\n",
       "273    1\n",
       "824    0\n",
       "11     1\n",
       "204    1\n",
       "897    0\n",
       "887    0\n",
       "949    0\n",
       "882    0\n",
       "851    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ulwljj5w1gVN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Credit_card (3).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
